{"ast":null,"code":"import \"core-js/modules/es.typed-array.find-last.js\";\nimport \"core-js/modules/es.typed-array.find-last-index.js\";\nimport { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport { jump, quick } from './jump.js';\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = quick[byt];\n    if (token === undefined) {\n      const decoder = jump[byt];\n      if (!decoder) {\n        throw new Error(`${decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, '0')})`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${decodeErrPrefix} non-string keys not supported (got ${typeof key})`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token = tokeniser.next();\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n  if (token.type.terminal) {\n    return token.value;\n  }\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n    throw new Error(`${decodeErrPrefix} tag not supported (${token.value})`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${decodeErrPrefix} data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${decodeErrPrefix} did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${decodeErrPrefix} got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${decodeErrPrefix} too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\nexport { Tokeniser, tokensToObject, decode };","map":{"version":3,"names":["decodeErrPrefix","Type","jump","quick","defaultDecodeOptions","strict","allowIndefinite","allowUndefined","allowBigInt","Tokeniser","constructor","data","options","pos","done","length","next","byt","token","undefined","decoder","Error","toString","padStart","minor","encodedLength","DONE","Symbol","for","BREAK","tokenToArray","tokeniser","arr","i","value","tokensToObject","Infinity","tokenToMap","useMaps","obj","m","Map","key","set","type","break","terminal","array","map","tag","tags","tagged","decode","Uint8Array","Object","assign","tokenizer","decoded"],"sources":["/Users/shepher/Downloads/filename-space/node_modules/cborg/esm/lib/decode.js"],"sourcesContent":["import { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport {\n  jump,\n  quick\n} from './jump.js';\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = quick[byt];\n    if (token === undefined) {\n      const decoder = jump[byt];\n      if (!decoder) {\n        throw new Error(`${ decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token = tokeniser.next();\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n  if (token.type.terminal) {\n    return token.value;\n  }\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n    throw new Error(`${ decodeErrPrefix } tag not supported (${ token.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\nexport {\n  Tokeniser,\n  tokensToObject,\n  decode\n};"],"mappings":";;AAAA,SAASA,eAAe,QAAQ,aAAa;AAC7C,SAASC,IAAI,QAAQ,YAAY;AACjC,SACEC,IAAI,EACJC,KAAK,QACA,WAAW;AAClB,MAAMC,oBAAoB,GAAG;EAC3BC,MAAM,EAAE,KAAK;EACbC,eAAe,EAAE,IAAI;EACrBC,cAAc,EAAE,IAAI;EACpBC,WAAW,EAAE;AACf,CAAC;AACD,MAAMC,SAAS,CAAC;EACdC,WAAW,CAACC,IAAI,EAAEC,OAAO,GAAG,CAAC,CAAC,EAAE;IAC9B,IAAI,CAACC,GAAG,GAAG,CAAC;IACZ,IAAI,CAACF,IAAI,GAAGA,IAAI;IAChB,IAAI,CAACC,OAAO,GAAGA,OAAO;EACxB;EACAE,IAAI,GAAG;IACL,OAAO,IAAI,CAACD,GAAG,IAAI,IAAI,CAACF,IAAI,CAACI,MAAM;EACrC;EACAC,IAAI,GAAG;IACL,MAAMC,GAAG,GAAG,IAAI,CAACN,IAAI,CAAC,IAAI,CAACE,GAAG,CAAC;IAC/B,IAAIK,KAAK,GAAGf,KAAK,CAACc,GAAG,CAAC;IACtB,IAAIC,KAAK,KAAKC,SAAS,EAAE;MACvB,MAAMC,OAAO,GAAGlB,IAAI,CAACe,GAAG,CAAC;MACzB,IAAI,CAACG,OAAO,EAAE;QACZ,MAAM,IAAIC,KAAK,CAAE,GAAGrB,eAAiB,8BAA8BiB,GAAG,KAAK,CAAG,YAAYA,GAAG,CAACK,QAAQ,CAAC,EAAE,CAAC,CAACC,QAAQ,CAAC,CAAC,EAAE,GAAG,CAAG,GAAE,CAAC;MAClI;MACA,MAAMC,KAAK,GAAGP,GAAG,GAAG,EAAE;MACtBC,KAAK,GAAGE,OAAO,CAAC,IAAI,CAACT,IAAI,EAAE,IAAI,CAACE,GAAG,EAAEW,KAAK,EAAE,IAAI,CAACZ,OAAO,CAAC;IAC3D;IACA,IAAI,CAACC,GAAG,IAAIK,KAAK,CAACO,aAAa;IAC/B,OAAOP,KAAK;EACd;AACF;AACA,MAAMQ,IAAI,GAAGC,MAAM,CAACC,GAAG,CAAC,MAAM,CAAC;AAC/B,MAAMC,KAAK,GAAGF,MAAM,CAACC,GAAG,CAAC,OAAO,CAAC;AACjC,SAASE,YAAY,CAACZ,KAAK,EAAEa,SAAS,EAAEnB,OAAO,EAAE;EAC/C,MAAMoB,GAAG,GAAG,EAAE;EACd,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGf,KAAK,CAACgB,KAAK,EAAED,CAAC,EAAE,EAAE;IACpC,MAAMC,KAAK,GAAGC,cAAc,CAACJ,SAAS,EAAEnB,OAAO,CAAC;IAChD,IAAIsB,KAAK,KAAKL,KAAK,EAAE;MACnB,IAAIX,KAAK,CAACgB,KAAK,KAAKE,QAAQ,EAAE;QAC5B;MACF;MACA,MAAM,IAAIf,KAAK,CAAE,GAAGrB,eAAiB,yCAAwC,CAAC;IAChF;IACA,IAAIkC,KAAK,KAAKR,IAAI,EAAE;MAClB,MAAM,IAAIL,KAAK,CAAE,GAAGrB,eAAiB,4CAA4CiC,CAAG,cAAcf,KAAK,CAACgB,KAAO,GAAE,CAAC;IACpH;IACAF,GAAG,CAACC,CAAC,CAAC,GAAGC,KAAK;EAChB;EACA,OAAOF,GAAG;AACZ;AACA,SAASK,UAAU,CAACnB,KAAK,EAAEa,SAAS,EAAEnB,OAAO,EAAE;EAC7C,MAAM0B,OAAO,GAAG1B,OAAO,CAAC0B,OAAO,KAAK,IAAI;EACxC,MAAMC,GAAG,GAAGD,OAAO,GAAGnB,SAAS,GAAG,CAAC,CAAC;EACpC,MAAMqB,CAAC,GAAGF,OAAO,GAAG,IAAIG,GAAG,EAAE,GAAGtB,SAAS;EACzC,KAAK,IAAIc,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGf,KAAK,CAACgB,KAAK,EAAED,CAAC,EAAE,EAAE;IACpC,MAAMS,GAAG,GAAGP,cAAc,CAACJ,SAAS,EAAEnB,OAAO,CAAC;IAC9C,IAAI8B,GAAG,KAAKb,KAAK,EAAE;MACjB,IAAIX,KAAK,CAACgB,KAAK,KAAKE,QAAQ,EAAE;QAC5B;MACF;MACA,MAAM,IAAIf,KAAK,CAAE,GAAGrB,eAAiB,uCAAsC,CAAC;IAC9E;IACA,IAAI0C,GAAG,KAAKhB,IAAI,EAAE;MAChB,MAAM,IAAIL,KAAK,CAAE,GAAGrB,eAAiB,0CAA0CiC,CAAG,uBAAuBf,KAAK,CAACgB,KAAO,GAAE,CAAC;IAC3H;IACA,IAAII,OAAO,KAAK,IAAI,IAAI,OAAOI,GAAG,KAAK,QAAQ,EAAE;MAC/C,MAAM,IAAIrB,KAAK,CAAE,GAAGrB,eAAiB,uCAAuC,OAAO0C,GAAK,GAAE,CAAC;IAC7F;IACA,MAAMR,KAAK,GAAGC,cAAc,CAACJ,SAAS,EAAEnB,OAAO,CAAC;IAChD,IAAIsB,KAAK,KAAKR,IAAI,EAAE;MAClB,MAAM,IAAIL,KAAK,CAAE,GAAGrB,eAAiB,0CAA0CiC,CAAG,yBAAyBf,KAAK,CAACgB,KAAO,GAAE,CAAC;IAC7H;IACA,IAAII,OAAO,EAAE;MACXE,CAAC,CAACG,GAAG,CAACD,GAAG,EAAER,KAAK,CAAC;IACnB,CAAC,MAAM;MACLK,GAAG,CAACG,GAAG,CAAC,GAAGR,KAAK;IAClB;EACF;EACA,OAAOI,OAAO,GAAGE,CAAC,GAAGD,GAAG;AAC1B;AACA,SAASJ,cAAc,CAACJ,SAAS,EAAEnB,OAAO,EAAE;EAC1C,IAAImB,SAAS,CAACjB,IAAI,EAAE,EAAE;IACpB,OAAOY,IAAI;EACb;EACA,MAAMR,KAAK,GAAGa,SAAS,CAACf,IAAI,EAAE;EAC9B,IAAIE,KAAK,CAAC0B,IAAI,KAAK3C,IAAI,CAAC4C,KAAK,EAAE;IAC7B,OAAOhB,KAAK;EACd;EACA,IAAIX,KAAK,CAAC0B,IAAI,CAACE,QAAQ,EAAE;IACvB,OAAO5B,KAAK,CAACgB,KAAK;EACpB;EACA,IAAIhB,KAAK,CAAC0B,IAAI,KAAK3C,IAAI,CAAC8C,KAAK,EAAE;IAC7B,OAAOjB,YAAY,CAACZ,KAAK,EAAEa,SAAS,EAAEnB,OAAO,CAAC;EAChD;EACA,IAAIM,KAAK,CAAC0B,IAAI,KAAK3C,IAAI,CAAC+C,GAAG,EAAE;IAC3B,OAAOX,UAAU,CAACnB,KAAK,EAAEa,SAAS,EAAEnB,OAAO,CAAC;EAC9C;EACA,IAAIM,KAAK,CAAC0B,IAAI,KAAK3C,IAAI,CAACgD,GAAG,EAAE;IAC3B,IAAIrC,OAAO,CAACsC,IAAI,IAAI,OAAOtC,OAAO,CAACsC,IAAI,CAAChC,KAAK,CAACgB,KAAK,CAAC,KAAK,UAAU,EAAE;MACnE,MAAMiB,MAAM,GAAGhB,cAAc,CAACJ,SAAS,EAAEnB,OAAO,CAAC;MACjD,OAAOA,OAAO,CAACsC,IAAI,CAAChC,KAAK,CAACgB,KAAK,CAAC,CAACiB,MAAM,CAAC;IAC1C;IACA,MAAM,IAAI9B,KAAK,CAAE,GAAGrB,eAAiB,uBAAuBkB,KAAK,CAACgB,KAAO,GAAE,CAAC;EAC9E;EACA,MAAM,IAAIb,KAAK,CAAC,aAAa,CAAC;AAChC;AACA,SAAS+B,MAAM,CAACzC,IAAI,EAAEC,OAAO,EAAE;EAC7B,IAAI,EAAED,IAAI,YAAY0C,UAAU,CAAC,EAAE;IACjC,MAAM,IAAIhC,KAAK,CAAE,GAAGrB,eAAiB,sCAAqC,CAAC;EAC7E;EACAY,OAAO,GAAG0C,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAEnD,oBAAoB,EAAEQ,OAAO,CAAC;EAC1D,MAAMmB,SAAS,GAAGnB,OAAO,CAAC4C,SAAS,IAAI,IAAI/C,SAAS,CAACE,IAAI,EAAEC,OAAO,CAAC;EACnE,MAAM6C,OAAO,GAAGtB,cAAc,CAACJ,SAAS,EAAEnB,OAAO,CAAC;EAClD,IAAI6C,OAAO,KAAK/B,IAAI,EAAE;IACpB,MAAM,IAAIL,KAAK,CAAE,GAAGrB,eAAiB,qCAAoC,CAAC;EAC5E;EACA,IAAIyD,OAAO,KAAK5B,KAAK,EAAE;IACrB,MAAM,IAAIR,KAAK,CAAE,GAAGrB,eAAiB,uBAAsB,CAAC;EAC9D;EACA,IAAI,CAAC+B,SAAS,CAACjB,IAAI,EAAE,EAAE;IACrB,MAAM,IAAIO,KAAK,CAAE,GAAGrB,eAAiB,0CAAyC,CAAC;EACjF;EACA,OAAOyD,OAAO;AAChB;AACA,SACEhD,SAAS,EACT0B,cAAc,EACdiB,MAAM"},"metadata":{},"sourceType":"module","externalDependencies":[]}